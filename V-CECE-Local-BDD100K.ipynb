{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "def download_image_from_url(url, filename):\n",
    "    img_data = requests.get(url).content\n",
    "    with open(filename, 'wb') as handler:\n",
    "        handler.write(img_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Hyperparameters of the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Hyperparameters of the experiment\n",
    "gradio_link = \"https://.....gradio.live\"\n",
    "\n",
    "# about the LVLM using AWS Bedrock\n",
    "aws_access_key_id= \"yours_aws_access_key_id\",\n",
    "aws_secret_access_key= \"yours_aws_secret_access_key\", \n",
    "region_name= \"yours_region_name\"\n",
    "model_id = \"anthropic.claude-3-5-sonnet-20241022-v2:0\" # model_id of the LVLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CECE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cece\n",
    "from cece.queries import *\n",
    "from cece.refine import *\n",
    "from cece.wordnet import *\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.06s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import sys\n",
    "# from BDD100k_classifier import BDD100k_classifier\n",
    "\n",
    "# classifier = BDD100k_classifier()\n",
    "\n",
    "from claude_predictor import *\n",
    "\n",
    "classification_prompt = f\"\"\"\n",
    "Classify each image in their appropriate class according to the driving situation they depict. \n",
    "Valid class labels are 'start' or 'stop' and only these, depending on whether the car has to move or stop based on its surroundings.\n",
    "You need to classify the images in one of these classes.\n",
    "Pay attention to the semantics that define each class.\n",
    "Return me only the label of the scene depicted and nothing else.\n",
    "\"\"\"\n",
    "\n",
    "prompt_analyze = \"\"\"\n",
    "Please analyze the images in detail and answer the following question with reason based on these images. \n",
    "\"\"\"\n",
    "\n",
    "text_prompt = f\"\"\"\n",
    "Based on your analysis above, classify each image in their appropriate class according to the driving situation they depict. \n",
    "Valid class labels are 'start' or 'stop' and only these, depending on whether the car has to move or stop based on its surroundings.\n",
    "Pay attention to the semantics that define each class.\n",
    "You need to classify the images in one of these classes.\n",
    "Return me only the label of the scene depicted and nothing else.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "image_names = os.listdir(\"bdd100k/images/10k/train/\")\n",
    "\n",
    "\n",
    "class Claude_classifier: \n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def classify(self, image_name):\n",
    "        source_classes = defaultdict(list)\n",
    "        pred = predict_classes_claude([image_name], source_classes, \n",
    "                                                classification_prompt, prompt_analyze, text_prompt, analyze=False)\n",
    "        pred = pred[image_name][0]\n",
    "        if pred == \"stop\":\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "classifier = Claude_classifier()    \n",
    "classifier.classify(\"bdd100k/images/10k/train/\" + image_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7000it [00:00, 41795.74it/s]\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "\n",
    "with open (\"BDD100K/bdd100k/labels/sem_seg/rles/sem_seg_train.json\") as handle:\n",
    "    segs = json.load(handle)\n",
    "    \n",
    "    \n",
    "dataset = []\n",
    "labels = []\n",
    "index_to_image_id = {}\n",
    "image_id_to_index = {}\n",
    "\n",
    "for i, row in tqdm(enumerate(segs[\"frames\"])):\n",
    "    objs = []\n",
    "    for obj in row[\"labels\"]:\n",
    "        objs.append(obj[\"category\"])\n",
    "    \n",
    "    dataset.append(objs.copy())\n",
    "    image_id = row[\"name\"]\n",
    "    labels.append(classifier.classify(os.path.join(\"bdd100k/images/10k/train\", image_id)))\n",
    "    index_to_image_id[i] = image_id\n",
    "    image_id_to_index[image_id] = i\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_text_edits(edits):\n",
    "    \"\"\"\n",
    "    Processes a dictionary of text edits by filtering and transforming elements based on specific criteria.\n",
    "\n",
    "    The function expects a dictionary with three keys: \"transf\", \"additions\", and \"removals\".\n",
    "    Each key should map to a list of elements (strings or list of strings).\n",
    "\n",
    "    The \"transf\" key is expected to contain a list of tuples, where each tuple represents a pair of word lists.\n",
    "    The function transforms each tuple by selecting the first word from each list in the pair that does not contain a period.\n",
    "\n",
    "    For the \"additions\" and \"removals\" keys, which map to lists of lists of strings, the function flattens these lists and includes only those elements that do not contain a period.\n",
    "\n",
    "    Parameters:\n",
    "        edits (dict): A dictionary containing three keys:\n",
    "            - \"transf\": A list of tuples, each containing two lists of words (word pairs).\n",
    "            - \"additions\": A list of lists, where each inner list contains words to be added.\n",
    "            - \"removals\": A list of lists, where each inner list contains words to be removed.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with the same structure as the input but filtered and transformed based on the criteria:\n",
    "            - \"additions\": List of words to be added, filtered to exclude words containing a period.\n",
    "            - \"removals\": List of words to be removed, filtered to exclude words containing a period.\n",
    "            - \"transf\": A list of transformed word pairs, each selected based on the absence of a period.\n",
    "    \"\"\"\n",
    "        \n",
    "    transf = []\n",
    "    for e1, e2 in edits[\"transf\"]:\n",
    "        ee1, ee2 = None, None\n",
    "        for e in e1:\n",
    "            if \".\" not in e:\n",
    "                ee1 = e\n",
    "                break\n",
    "                \n",
    "        for e in e2:\n",
    "            if \".\" not in e:\n",
    "                ee2 = e\n",
    "                break\n",
    "        transf.append([ee1, ee2])\n",
    "        \n",
    "    return {\n",
    "        \"additions\": [ee for e in edits[\"additions\"] for ee in e if \".\" not in ee],\n",
    "        \"removals\": [ee for e in edits[\"removals\"] for ee in e if \".\" not in ee],\n",
    "        \"transf\": transf\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cece.xDataset import *\n",
    "from cece.xDataset import createMSQ\n",
    "\n",
    "msq_dataset = []\n",
    "for row in dataset:\n",
    "    msq = []\n",
    "    for obj in row:\n",
    "        try:\n",
    "            msq.append(connect_term_to_wordnet(obj).union([obj]))\n",
    "        except:\n",
    "            try:\n",
    "                msq.append(connect_term_to_wordnet(obj.replace(\" \", \"\")).union([obj.replace(\" \", \"\")]))\n",
    "            except:\n",
    "                pass\n",
    "    msq_dataset.append(msq.copy())\n",
    "\n",
    "ds = xDataset(dataset = msq_dataset,\n",
    "              labels = labels,\n",
    "              connect_to_wordnet = False)\n",
    "\n",
    "\n",
    "def get_local_edits(image_id):\n",
    "    \"\"\"\n",
    "    Retrieves and processes local edits between two images in a dataset based on their semantic differences.\n",
    "\n",
    "    This function identifies the source image by its image_id, then finds the corresponding target image using\n",
    "    a domain-specific explanation system that prioritizes minimal semantic change (cost). The function retrieves \n",
    "    the edits between the source and target images, transforms these edits using the export_text_edits function,\n",
    "    and compiles the lists of added and removed objects based on these transformations.\n",
    "\n",
    "    Parameters:\n",
    "        image_id (int or str): The identifier for the source image in the dataset. This ID is used to find\n",
    "                               the corresponding source index, and subsequently, the target image and edits.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing three elements:\n",
    "            - source_image_id (str or int): The ID of the source image.\n",
    "            - added_objs (list): A list of objects added in the transition from the source to the target image.\n",
    "            - removed_objs (list): A list of objects removed in the transition from the source to the target image.\n",
    "\n",
    "    The function relies on several global data structures:\n",
    "        - image_id_to_index (dict): Maps image IDs to their respective indices in the dataset.\n",
    "        - index_to_image_id (dict): Maps dataset indices back to image IDs.\n",
    "        - ds (object): A dataset object that contains methods to explain differences between images and find edits.\n",
    "        - labels (list): A list of labels for the images in the dataset, used in the explanation process.\n",
    "    \"\"\"\n",
    "    source_index = image_id_to_index[image_id]\n",
    "    source_image_id = index_to_image_id[source_index]\n",
    "    objects_source = [dd for d in ds.dataset[source_index].concepts for dd in d if \".\" not in dd]\n",
    "\n",
    "    target_index, cost = ds.explain(ds.dataset[source_index], labels[source_index])\n",
    "    target_image_id = index_to_image_id[target_index]\n",
    "    cost, edits = ds.find_edits(ds.dataset[source_index], ds.dataset[target_index])\n",
    "    \n",
    "    edits = export_text_edits(edits)\n",
    "    added_objs = edits[\"additions\"] + [e for [_, e] in edits[\"transf\"]]\n",
    "    removed_objs = edits[\"removals\"] + [e for [e, _] in edits[\"transf\"]]\n",
    "    return objects_source, added_objs, removed_objs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from edits import Edits\n",
    "import ast\n",
    "from editor import Editor\n",
    "import boto3\n",
    "from chat import Chat\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "editor = Editor(gradio_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LVLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the aws runtime and model\n",
    "bedrock_runtime_client = boto3.client(\n",
    "    'bedrock-runtime',\n",
    "    aws_access_key_id=  aws_access_key_id,\n",
    "    aws_secret_access_key= aws_secret_access_key,\n",
    "    region_name=region_name\n",
    ")\n",
    "\n",
    "model_id = model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Claude decide the edits!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts import prompt_single_step_bdd100k\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def create_or_replace_dir(directory_name):\n",
    "    # Check if the directory already exists\n",
    "    if os.path.exists(directory_name):\n",
    "        # If it exists, remove it\n",
    "        shutil.rmtree(directory_name)\n",
    "    \n",
    "    # Create the new directory\n",
    "    os.makedirs(directory_name)\n",
    "\n",
    "def edit_claude_single_step(image_id):\n",
    "    \n",
    "    create_or_replace_dir(f\"imgs/bdd100k/claude-haiku/claude/{image_id}\")\n",
    "    source_image_path = f\"imgs/bdd100k/claude-haiku/claude/{image_id}/source.jpg\"\n",
    "    \n",
    "    url = data[image_id][\"url\"]\n",
    "\n",
    "    shutil.copyfile(url, source_image_path)\n",
    "    steps = []\n",
    "    \n",
    "    # read the objects \n",
    "    objs, added_objs, removed_objs = get_local_edits(image_id)\n",
    "    \n",
    "    chat = Chat(model_id, bedrock_runtime_client)\n",
    "\n",
    "    logs = \"\"\n",
    "    excs, i = 0, 1\n",
    "    orig_label = classify(source_image_path)\n",
    "    logs += f\"Classification: {orig_label}\\n\"\n",
    "    new_label = orig_label\n",
    "    while (new_label == orig_label):\n",
    "        try:\n",
    "            prompt = prompt_single_step_bdd100k(objs, added_objs,removed_objs)\n",
    "\n",
    "            chat.add_user_message_image(prompt, source_image_path) # add a user message with an image and a text prompt\n",
    "            step = chat.generate().split(\"-\")[0].strip()\n",
    "            logs += f\"\\n----\\nOutput LVLM: {i}\\n{step}\\n\"\n",
    "            step = ast.literal_eval(step.split(\"\\n\")[0])\n",
    "            logs += f\"Step: {i}\\n{step}\\n\"\n",
    "            if step[0].lower() == \"add\":\n",
    "                new_image, mask = editor.replacer(source_image_path, step[2], step[1])\n",
    "                if step[1] in added_objs:\n",
    "                    added_objs.remove(step[1])\n",
    "                objs.append(step[1])\n",
    "                steps.append(step)\n",
    "\n",
    "            elif step[0].lower() == \"remove\":\n",
    "                new_image, mask = editor.replacer(source_image_path, step[1], step[2])\n",
    "                if step[1] in removed_objs:\n",
    "                    removed_objs.remove(step[1])\n",
    "                if step[1] in objs:\n",
    "                    objs.remove(step[1])\n",
    "                    \n",
    "                steps.append(step)\n",
    "\n",
    "            elif step[0].lower() == \"replace\":\n",
    "                new_image, mask = editor.replacer(source_image_path, step[1], step[2])\n",
    "                if step[2] in added_objs:\n",
    "                    added_objs.remove(step[2])\n",
    "                objs.append(step[2])\n",
    "\n",
    "                if step[1] in removed_objs:\n",
    "                    removed_objs.remove(step[1])\n",
    "                if step[1] in objs:\n",
    "                    objs.remove(step[1])\n",
    "                    \n",
    "                steps.append(step)\n",
    "            else:\n",
    "                print (\"Unknown action!\")\n",
    "                return \n",
    "\n",
    "            source_image_path = f\"imgs/bdd100k/claude-haiku/claude/{image_id}/step_{i}.jpg\"\n",
    "            new_image.save(source_image_path)\n",
    "            i += 1\n",
    "            new_label = classifier.classify(source_image_path)\n",
    "            logs += f\"Classification: {new_label}\\n\"\n",
    "\n",
    "        except Exception as e:\n",
    "            excs += 1\n",
    "            logs += f\"Exception: {e}\\n\"\n",
    "            if excs >= 5:\n",
    "                break\n",
    "\n",
    "    logs += f\"\\n\\n----\\n\\n{steps}\\n\\n----\\n\\n\"\n",
    "    with open(f\"imgs/bdd100k/claude-haiku/claude/{image_id}/logs.txt\", \"w\") as handle:\n",
    "        handle.write(logs)\n",
    "    return steps\n",
    "        \n",
    "    \n",
    "def classified_as(image_path, cl):\n",
    "    preds = classifier.classify(image_path)\n",
    "    if preds == cl:\n",
    "        return True\n",
    "    return False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "    \n",
    "for key in tqdm(list(data.keys())):\n",
    "    edit_claude_single_step(key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_3.10.12",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
